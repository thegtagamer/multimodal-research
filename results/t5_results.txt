(multimodal) [adey6@gpu021 multimodal-research]$ python eval_t5.py
Using device: cuda
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Total files loaded: 1752
âœ… Loaded model checkpoint.
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1752/1752 [04:20<00:00,  6.72it/s]

ðŸŽ¯ Evaluation Metrics:
Accuracy: 0.7505
Precision: 0.8179
Recall: 0.7505
F1: 0.7519
âœ… Results saved to t5_evaluation_results.json
